{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models on sentiment analysis\n",
    "\n",
    "Note: training dataset: 90%, testing dataset: 10%\n",
    "\n",
    "### Analysis results for existing libs\n",
    "\n",
    "* Trainning Dataset: /100k-courseras-course-reviews-dataset/reviews_train.csv\n",
    "  * totalCnt: 96316, #1 = 2,122, #2 = 1,922, #3 = 4,427, #4 = 16,078, #5 = 71,767\n",
    "  * vaderErr = 35,345, textBlobErr = 57,552, stanfordNlpErr = 75,420\n",
    "\n",
    "| Tables   |  total_acc  |  #5_acc |  #4_acc |  #3_acc |  #2_acc |  #1_acc |\n",
    "|---------- |:-----------:|--------:|--------:|--------:|--------:|--------:|\n",
    "| VaderSent |  63.3%    | 76.7%   |  26.9%  |  14.7%  |  21.9%  |  24.5%  |\n",
    "| TextBlob  |  40.2%    | 37.6%   |  65.6%  |  15.3%  |  22.3%  |  05.5%  |\n",
    "| SCoreNLP  |  21.7%    | 13.0%   |  57.9%  |  18.0%  |  66.5%  |  07.7%  |\n",
    "| ~PatternE~  |  40.2%    | 37.6%   |  65.6%  |  15.6%  |  22.8%  |  05.5%  |\n",
    "| LingPipe  |  76.5%    |\n",
    "\n",
    "* Testing Dataset:\n",
    "  * totalCnt= 10702 , vaderErr= 4280 , textBlobErr= 6525 , stanfordNlpErr= 8321\n",
    "  \n",
    "Notes: \n",
    "- compute the StanfordNLP score on training dataset took > 4 hours\n",
    "- TextBlob seems same with Pattern, they could use same ML algo\n",
    "\n",
    "### Combination Model with Random Forest Classifier\n",
    "\n",
    "* RFC with `n_estimators=30` on training dataset with 3 libs\n",
    "  * acc on training dataset: 91.0%\n",
    "  * acc on testing dataset: 67.3%\n",
    "* RFC with `n_estimators=30` on training dataset with 4 libs (with the LingPipe feature from Anthony!!)\n",
    "  * acc on training dataset: 94.2%\n",
    "  * acc on testing dataset: 85.1%\n",
    " \n",
    "TODO/Improvements:\n",
    "1. pre-process the reviews\n",
    "2. more features\n",
    "3. adjust RFC super params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def divideDataSet(file, totalCount, percent):\n",
    "    divider = totalCount * percent\n",
    "    count = 0\n",
    "    with open(file, newline='', encoding='utf-8') as inputfile:\n",
    "        reader = csv.DictReader(inputfile)\n",
    "        with open('./test.csv', 'w', newline='', encoding='utf-8') as trainfile:\n",
    "            fieldnames = ['Id', 'Review', 'Label']\n",
    "            trainWriter = csv.DictWriter(trainfile, fieldnames = fieldnames)  \n",
    "            trainWriter.writeheader()\n",
    "            for row in reader:\n",
    "                count += 1\n",
    "                if count > divider:\n",
    "                    trainWriter.writerow({'Id': row['Id'], 'Review': row['Review'], 'Label':row['Label']})\n",
    "                \n",
    "           \n",
    "divideDataSet('../100k-courseras-course-reviews-dataset/reviews.csv', 107018, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalCnt= 10702 , vaderErr= 4280 , textBlobErr= 6525 , stanfordNlpErr= 8321\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "vaderAnalyser = SentimentIntensityAnalyzer()\n",
    "stanfordNlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def convertScore(score):\n",
    "    label = 0\n",
    "    if score > 0.525:\n",
    "        label = 5\n",
    "    elif score <= 0.525 and score >= 0.05:\n",
    "        label = 4\n",
    "    elif score < 0.05 and score > -0.05:\n",
    "        label = 3\n",
    "    elif score <= -0.05 and score >= -0.525:\n",
    "        label = 2\n",
    "    else:\n",
    "        label = 1\n",
    "        \n",
    "    return label\n",
    "    \n",
    "    \n",
    "def computeScore(file):\n",
    "    totalCnt = 0\n",
    "    vaderErr = 0\n",
    "    textBlobErr = 0\n",
    "    stanfordNlpErr = 0\n",
    "    with open(file, newline='', encoding='utf-8') as inputfile:\n",
    "        reader = csv.DictReader(inputfile)\n",
    "        with open('./reviews_test_predict_v0.3.csv', 'w', newline='', encoding='utf-8') as trainfile:\n",
    "            fieldnames = ['Id', 'Review', 'Label', 'VaderScore', 'VaderLabel', 'TextBlobScore', 'TextBlobLabel', 'StanfordnlpScore', 'StanfordnlpLabel']\n",
    "            trainWriter = csv.DictWriter(trainfile, fieldnames = fieldnames)  \n",
    "            trainWriter.writeheader()\n",
    "            for row in reader:\n",
    "                totalCnt += 1\n",
    "#                 if totalCnt >= 10:\n",
    "#                     continue\n",
    "                # compute stanford CoreNLP score\n",
    "                output = stanfordNlp.annotate(row['Review'], properties={\n",
    "                            'annotators': 'sentiment',\n",
    "                            'outputFormat': 'json'\n",
    "                        })\n",
    "                stanfordScore = output['sentences'][0]['sentimentValue']\n",
    "                stanfordLabel = int(stanfordScore) + 1\n",
    "                stanfordSentiment = output['sentences'][0]['sentiment']\n",
    "#                 if int(stanfordScore) < 1:\n",
    "#                     print('Label=', row['Label'], ', stanfordScore=', stanfordScore, ', stanfordSentiment=', stanfordSentiment, ', row=', row)\n",
    "                \n",
    "                # compute vader score\n",
    "                vaderScore = vaderAnalyser.polarity_scores(row['Review'])['compound']\n",
    "                vaderLabel = convertScore(vaderScore)\n",
    "                # compute textblob score\n",
    "                testimonial = TextBlob(row['Review'])\n",
    "                textBlobScore = testimonial.sentiment.polarity\n",
    "                textBlobLabel = convertScore(textBlobScore)\n",
    "                \n",
    "                labelErr = False\n",
    "                if vaderLabel != int(row['Label']):\n",
    "                    vaderErr += 1\n",
    "                    labelErr = True\n",
    "                if textBlobLabel != int(row['Label']):\n",
    "                    textBlobErr += 1\n",
    "                    labelErr = True\n",
    "                if stanfordLabel != int(row['Label']):\n",
    "                    stanfordNlpErr += 1\n",
    "                    labelErr = True\n",
    "#                 if labelErr:\n",
    "#                     print('Label=', row['Label'], ', vaderCompound=', vaderCompound, ', vaderLabel=', vaderLabel, ', textBlobScore=', textBlobScore, ', textBlobLabel=', textBlobLabel, ', row=', row)\n",
    "                trainWriter.writerow({'Id': row['Id'], 'Review': row['Review'], 'Label':row['Label'], \n",
    "                                      'VaderScore': vaderScore, 'VaderLabel': vaderLabel, \n",
    "                                      'TextBlobScore': textBlobScore, 'TextBlobLabel': textBlobLabel,\n",
    "                                      'StanfordnlpScore': stanfordScore, 'StanfordnlpLabel': stanfordLabel\n",
    "                                     })\n",
    "      \n",
    "    #totalCnt= 96316 , vaderErr= 35345 (36.7%), textBlobErr= 57552 (59.7%), stanfordNlpErr= 75420(21.7%) on training data set\n",
    "    #totalCnt= 10702 , vaderErr= 4280 , textBlobErr= 6525 , stanfordNlpErr= 8321 on testing data set\n",
    "    \n",
    "    print('totalCnt=', totalCnt, ', vaderErr=', vaderErr, ', textBlobErr=', textBlobErr, ', stanfordNlpErr=', stanfordNlpErr)\n",
    "            \n",
    "computeScore('../100k-courseras-course-reviews-dataset/reviews_test.csv')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pattern\n",
    "\n",
    "import pandas as pd\n",
    "from pattern.en import sentiment\n",
    "\n",
    "data_train = pd.read_csv('./reviews_train_predict_v0.2.csv')\n",
    "\n",
    "data_train['PatternScore'] = data_train['Review'].apply(lambda x: sentiment(x)[0])\n",
    "data_train['PatternLabel'] = data_train['PatternScore'].apply(lambda x: convertScore(x))\n",
    "\n",
    "data_train.to_csv('./reviews_train_predict_v0.3.csv', encoding='utf-8')\n",
    "\n",
    "data_test = pd.read_csv('./reviews_test_predict_v0.2.csv')\n",
    "\n",
    "data_test['PatternScore'] = data_test['Review'].apply(lambda x: sentiment(x)[0])\n",
    "data_test['PatternLabel'] = data_test['PatternScore'].apply(lambda x: convertScore(x))\n",
    "\n",
    "data_test.to_csv('./reviews_test_predict_v0.3.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2122, 1922, 4427, 16078, 71767]\n",
      "[117, 439, 692, 10540, 26954]\n",
      "[0.05513666352497644, 0.22840790842872008, 0.15631353060763498, 0.6555541734046523, 0.37557651845555756]\n",
      "pattern total acc: 0.4022384650525354\n",
      "[117, 429, 678, 10542, 26998]\n",
      "[0.05513666352497644, 0.22320499479708636, 0.15315111813869436, 0.6556785669859435, 0.37618961361071246]\n",
      "TextBlob total acc: 0.4024668798538145\n"
     ]
    }
   ],
   "source": [
    "### Compute accuracy\n",
    "\n",
    "data = pd.read_csv('./reviews_train_predict_v0.3.csv')\n",
    "\n",
    "totalCnt = [ data[data['Label'] == i].shape[0] for i in range(1,6)]\n",
    "print(totalCnt)\n",
    "\n",
    "# Pattern\n",
    "patternCnt = [ data[(data['Label'] == i) & (data['PatternLabel'] == i)].shape[0] for i in range(1,6)]\n",
    "print(patternCnt)\n",
    "\n",
    "patternAcc = [patternCnt[i]/totalCnt[i] for i in range(0,5)]\n",
    "print(patternAcc)\n",
    "\n",
    "print('pattern total acc:', sum(patternCnt)/sum(totalCnt))\n",
    "\n",
    "# TextBlob\n",
    "textBlobCnt = [ data[(data['Label'] == i) & (data['TextBlobLabel'] == i)].shape[0] for i in range(1,6)]\n",
    "print(textBlobCnt)\n",
    "\n",
    "textBlobAcc = [textBlobCnt[i]/totalCnt[i] for i in range(0,5)]\n",
    "print(textBlobAcc)\n",
    "\n",
    "print('TextBlob total acc:', sum(textBlobCnt)/sum(totalCnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For total #reviews= 96316\n",
      "the top 1 frequent word  good  appears  17000 times\n",
      "Got total top frequent #words= 78299\n"
     ]
    }
   ],
   "source": [
    "### Naive Bayes classifier - extract features from reviews of training data set\n",
    "import timeit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def clean_review(review):\n",
    "    words_filtered = [e.lower() for e in review.split() if len(e) >= 3]\n",
    "    words_without_stopwords = [word for word in words_filtered if not word in stopwords_set]\n",
    "    return words_without_stopwords\n",
    "\n",
    "def clean_reviews(train):\n",
    "    reviews = []\n",
    "    for index, row in train.iterrows():\n",
    "        words_without_stopwords = clean_review(row['Review'])\n",
    "        reviews.append(words_without_stopwords)\n",
    "        \n",
    "    return reviews\n",
    "\n",
    "# Extracting word features\n",
    "def get_words_in_reviews(reviews):\n",
    "    all = []\n",
    "    for review in reviews:\n",
    "        all.extend(review)\n",
    "    return all\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    features = wordlist.keys()\n",
    "    print('the top 1 frequent word ',list(features)[0], ' appears ', wordlist[list(features)[0]], 'times')\n",
    "    # extract 78299 top words from total 1285873 words\n",
    "    return features\n",
    "\n",
    "data_train = pd.read_csv('./reviews_train_predict_v0.3.csv')\n",
    "reviews = clean_reviews(data_train)\n",
    "print('For total #reviews=', len(reviews))\n",
    "w_features = get_word_features(get_words_in_reviews(reviews))\n",
    "print('Got total top frequent #words=', len(w_features))\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "#     features = {}\n",
    "    digit_features = []\n",
    "    for word in w_features:\n",
    "#         features['contains(%s)' % word] = (word in document_words)\n",
    "        digit_feature = 1 if word in document_words else 0\n",
    "        digit_features.append(digit_feature)\n",
    "    return digit_features\n",
    "\n",
    "# features = extract_features(reviews[0])\n",
    "# print('reviews[0]: ', reviews[0])\n",
    "# print('features: ', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-d86e6d4ef0e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(X.shape, y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-d86e6d4ef0e6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(X.shape, y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-70e76dd1c2aa>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(document)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mdigit_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mw_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'contains(%s)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mdigit_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument_words\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mdigit_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigit_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "X = [extract_features(review) for review in reviews]\n",
    "y = data_train['Label']\n",
    "# print(X.shape, y.shape)\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X, y)\n",
    "pickle.dump(rfcModel, open('NultinomialNB_train_v0.3.model', 'wb'))\n",
    "\n",
    "print(mnb_model.predict(X[0:1]))\n",
    "                               \n",
    "stop = timeit.default_timer()\n",
    "print('Trainning model took(s): ', stop - start)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Naive Bayes classifier - evaluate the model\n",
    "\n",
    "scores=mnb_model.score(X, y)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id                                             Review  Label  \\\n",
      "0  96316  This course can be a bit dry at times. But sti...      4   \n",
      "1  96317                                  awesome course...      4   \n",
      "2  96318                     Good course with great teacher      5   \n",
      "3  96319  Great intro to bootstrap. I feel like more boo...      4   \n",
      "\n",
      "   VaderScore  VaderLabel  TextBlobScore  TextBlobLabel  StanfordnlpScore  \\\n",
      "0      0.0000           3       0.066667              4                 1   \n",
      "1      0.6249           5       1.000000              5                 2   \n",
      "2      0.7906           5       0.750000              5                 3   \n",
      "3      0.7650           5       0.650000              5                 3   \n",
      "\n",
      "   StanfordnlpLabel  Unnamed: 0  Id_lingpipe  \\\n",
      "0                 2       96316        96316   \n",
      "1                 3       96317        96317   \n",
      "2                 4       96318        96318   \n",
      "3                 4       96319        96319   \n",
      "\n",
      "                                     Review_lingpipe  Label_lingpipe  \\\n",
      "0  This course can be a bit dry at times. But sti...               4   \n",
      "1                                  awesome course...               4   \n",
      "2                     Good course with great teacher               5   \n",
      "3  Great intro to bootstrap. I feel like more boo...               4   \n",
      "\n",
      "   LingPipeLabel  \n",
      "0              4  \n",
      "1              5  \n",
      "2              5  \n",
      "3              4  \n"
     ]
    }
   ],
   "source": [
    "### extract LingPipe feature\n",
    "\n",
    "# lingpipe_data = pd.read_csv('./lingPipe.csv', encoding='ISO-8859-1')\n",
    "# lingpipe_data.to_csv('./lingPipe_v2.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "lingpipe_data=pd.read_csv('./lingPipe_v2.csv', encoding='utf-8')\n",
    "others_data = pd.read_csv('./reviews_test_predict_v0.2.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "combine_data = others_data.join(lingpipe_data, on=['Id'], how='left', rsuffix='_lingpipe')\n",
    "print(combine_data[0:4])\n",
    "combine_data = combine_data[['Id', 'Review', 'Label', 'VaderScore', 'VaderLabel', 'TextBlobScore', 'TextBlobLabel', 'StanfordnlpScore', 'StanfordnlpLabel', 'LingPipeLabel']]\n",
    "combine_data.to_csv('reviews_test_predict_v0.4.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis results for existing libs\n",
    "\n",
    "* Trainning Dataset: /100k-courseras-course-reviews-dataset/reviews_train.csv\n",
    "  * totalCnt: 96316, #1 = 2,122, #2 = 1,922, #3 = 4,427, #4 = 16,078, #5 = 71,767\n",
    "  * vaderErr = 35,345, textBlobErr = 57,552, stanfordNlpErr = 75,420\n",
    "\n",
    "| Tables   |  total_acc  |  #5_acc |  #4_acc |  #3_acc |  #2_acc |  #1_acc |\n",
    "|---------- |:-----------:|--------:|--------:|--------:|--------:|--------:|\n",
    "| VaderSent |  63.3%    | 76.7%   |  26.9%  |  14.7%  |  21.9%  |  24.5%  |\n",
    "| TextBlob  |  40.2%    | 37.6%   |  65.6%  |  15.3%  |  22.3%  |  05.5%  |\n",
    "| SCoreNLP  |  21.7%    | 13.0%   |  57.9%  |  18.0%  |  66.5%  |  07.7%  |\n",
    "| PatternE  |  40.2%    | 37.6%   |  65.6%  |  15.6%  |  22.8%  |  05.5%  |\n",
    "\n",
    "* Testing Dataset:\n",
    "  * totalCnt= 10702 , vaderErr= 4280 , textBlobErr= 6525 , stanfordNlpErr= 8321\n",
    "  \n",
    "Notes: \n",
    "- compute the StanfordNLP score on training dataset took > 4 hours\n",
    "- TextBlob seems same with Pattern, they could use same ML algo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination Model with Random Forest Classifier\n",
    "\n",
    "* RFC with `n_estimators=30` on training dataset with 3 libs\n",
    "  * acc on training dataset: 91.0%\n",
    "  * acc on testing dataset: 67.3%\n",
    "* RFC with `n_estimators=30` on training dataset with 4 libs\n",
    "  * acc on training dataset: 91.1%\n",
    "  * acc on testing dataset: 66.6%\n",
    " \n",
    "Improvements:\n",
    "1. more libs as classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9423148801860542\n",
      "Trainning model took(s):  4.9431297999981325\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start = timeit.default_timer()\n",
    "data = pd.read_csv('./reviews_train_predict_v0.4.csv')\n",
    "\n",
    "X = data[['VaderScore', 'VaderLabel', 'TextBlobScore', 'TextBlobLabel', 'StanfordnlpScore', 'StanfordnlpLabel', 'LingPipeLabel']].values\n",
    "y = data['Label'].values\n",
    "\n",
    "n_estimators = 30\n",
    "rfcModel = RandomForestClassifier(n_estimators=n_estimators)\n",
    "rfcModel.fit(X, y)\n",
    "\n",
    "pickle.dump(rfcModel, open('rfc_train_v0.4.model', 'wb'))\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "scores = rfcModel.score(X, y)\n",
    "print(scores) \n",
    "stop = timeit.default_timer()\n",
    "print('Trainning model took(s): ', stop - start)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8518968417118296\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./reviews_test_predict_v0.4.csv')\n",
    "X_test = test[['VaderScore', 'VaderLabel', 'TextBlobScore', 'TextBlobLabel', 'StanfordnlpScore', 'StanfordnlpLabel', 'LingPipeLabel']].values\n",
    "y_test = test['Label'].values\n",
    "scores_test = rfcModel.score(X_test, y_test)\n",
    "print(scores_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Demo \n",
    "\n",
    "loaded_model = pickle.load(open('rfc_train_v0.4.model', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
